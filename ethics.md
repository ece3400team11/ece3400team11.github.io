# Ethics Homework

## Prompt

Is "a ban on offensive autonomous weapons beyond meaningful human control" going to work?

## Response

As technology continues to advance, more and more aspects of life and human interactions are becoming increasingly automated. From the advent of assembly lines and steam power in the first industrial revolution, to machine learning algorithms that are able to help doctors diagnose patients, less work is being done by humans and more work is being left as tasks to intelligent autonomous systems. As we continue to progress, these trends will continue to spread to other fields, including warfare. Many believe that the use of such weapons would lower the threshold for going to battle due to the disconnection that occurs between the users of the technology and the subsequent carnage and destruction brought about by it. Because of these concerns, prominent artificial Intelligence and robotics researchers—including Stephen Hawking and Elon Musk—have signed an open letter asking for a ban on offensive autonomous weapons beyond meaningful human control.  A ban on offensive autonomous weapons beyond human control would not be effective for practical, ethical, and economical reasons.

Since these weapons already exist and countries are going to great lengths to develop them, it would be extremely difficult to enforce this ban. Countries want to have a stockpile of autonomous weapons, similar to nuclear weapons, because it is a winning strategy to build them and then use them as a deterrent. And since these robots can be cheap to implement, there isn’t a physical limit stopping the development of these robots. As the cost of developing and building powerful autonomous weapons continues to decrease, more and more people will have the access and ability to build these weapons. Some of these people may not have the best intentions in mind. One can imagine small groups with a bit of funding building cheap autonomous drones with a lethal explosive attached, like the fictitious Slaughterbot drones ([link](https://autonomousweapons.org/slaughterbots/)). The video describes a new autonomous drone with facial recognition technology equipped with an explosive charge that can seek out individuals and kill them. The point of the video is that the individual technologies to build these killer drones (facial recognition, small explosive charges, quadcopters capable of autonomous navigation) already exist, so it is feasible that a terrorist organization can build these drones in the near future. Thought experiments like this definitely raise alarm and should encourage world leaders to search for a way to deal with autonomous weapons in the future. However, the Slaughterbots video also shows how a simple ban will likely not be effective in stopping the advancement of autonomous weapons systems.

Ethically, putting a ban on autonomous weapons may put to halt to all autonomous systems. This would not be ideal because autonomous systems can do a lot of good such as self driving cars, elderly care, etc. And even if they can be seen as dangerous weapons, they are necessary for their intended purpose. For example, lasers in space can be be used as weapons for warfare but they are necessary to clean up debris. And even if placing the ban was completely ethical, it has never been effective in the past, recently shown through North Korea.

Economically, placing a ban on autonomous weapons would shut down a growing market that already has a lot of money poured into. The market includes a partial to fully autonomous weapon that requires no human interaction, meaning it doesn’t need to make decisions completely by itself to be considered autonomous (functional morality). And since many of these companies are tied to academic institutions, it would be hard to separate research from actual use.

In conclusion, while we need solutions to handle the increasing use of autonomous weapons, a flat out ban it not feasible and will likely be ineffective at preventing the development and use of autonomous weapons. Instead, we need to focus on regulating these systems and conduct research into countermeasures against various autonomous weapons.
